I"Õ<h2 id="source-feature-pyramid-networks-for-object-detection-paper-link">source: Feature Pyramid Networks for Object Detection <a href="https://arxiv.org/abs/1612.03144">(paper link)</a></h2>

<h2 id="list-of-contents">List of contents</h2>
<ol>
  <li>Introduction</li>
  <li>Feature Pyramids structure</li>
  <li>Network details</li>
  <li>Applications</li>
  <li>Experiments</li>
  <li>Conclusion</li>
</ol>

<h2 id="introduction">Introduction</h2>
<p>Â Â Â Â  In this paper, authors introduce the multi-scale, pyramidal hierarchy of deep convolutional networks to construct <strong>feature pyramids</strong> with marginal extra cost. Using FPN in a basic Faster R-CNN system, the method achieves the best single-model performance on the COCO detection benchmark surpassing all existing models in 2017.</p>

<h2 id="feature-pyramids-structure">Feature Pyramids structure</h2>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858577-aabbf480-12d5-11ea-8a23-c0cb7d42d74e.png" /></div>

<p>The advantage of featurizing each level of an image pyramid is that it produces a multi-scale feature representation in which all levels are semantically strong, including the high-resolution levels.</p>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858580-abed2180-12d5-11ea-90b6-178e56b36c8b.png" /></div>

<p>In a featurized image network, we use an pyramid of images. Since we use multiple images of different scales to output a prediction, the inference time increases multiple times. This causes a long computational time and makes the model impractical for real applications.</p>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858583-ad1e4e80-12d5-11ea-9ca4-0c11ac8a0636.png" /></div>

<p>The single feature map uses the single scale features for faster detection. This is the basic structure of recent CNN models and has a short computational time. However, it cannot achieve the most accurate results because it loses much of spatial and semantic information in the lower level features.</p>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858591-aee81200-12d5-11ea-884d-47c0d793918e.png" /></div>

<p>An alternative is to reuse the pyramidal feature hierarchy computed by a CNN as if it were a featurized image pyramid. However, the prediction for each scale is done independently.</p>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858594-b14a6c00-12d5-11ea-8c3e-3c17063110d3.png" /></div>

<p>Feature Pyramid Network (FPN) is probably better, and it performs fast and accurately. This model leverage the pyramidal shape of a ConvNetâ€™s feature hierarchy while creating a feature pyramid that has <strong>strong semantics at all scales</strong>. It combines low-resolution, semantically strong features with high-resolution, semantically weak features via a top-down pathway and lateral connections.</p>

<h2 id="network-details">Network details</h2>

<blockquote>
  <p>Bottom-up pathway</p>
</blockquote>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858602-b3acc600-12d5-11ea-9111-baf7745d650e.png" /></div>

<p>Â Â Â Â  The bottom-up pathway is the feedforward computation of the backbone ConvNet, which computes a <strong>feature hierarchy</strong> consisting of feature maps at several scales with a scaling step of 2. There are often many layers producing output maps of the same size and we say these layers are in the same network stage.</p>

<blockquote>
  <p>Top-down pathway</p>
</blockquote>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858602-b3acc600-12d5-11ea-9111-baf7745d650e.png" /></div>

<p>We upsample the spatial resolution by a factor of 2 (using nearest neighbor upsampling for simplicity). The upsampled map is then merged with the corresponding bottom-up channel dimensions by element-wise addition. (which undergoes a 1Ã—1 convolutional layer to reduce channel dimensions) This process is iterated until the finest resolution map is generated.</p>

<h2 id="applications">Applications</h2>

<blockquote>
  <p>Feature Pyramid Networks for RPN</p>
</blockquote>

<p>Â Â Â Â  RPN(Region Proposal Network) is a sliding-window class-agnostic object detector. In the original RPN design, a small subnetwork is evaluated on dense <strong>3Ã—3 sliding windows</strong>, on top of a single-scale convolutional feature map, performing <strong>object/non-object binary classification</strong> and <strong>bounding box regression</strong>. This is realized by a 3Ã—3 convolutional layer followed by two sibling 1Ã—1 convolutions for classification and regression, which we refer to as a <strong>network head</strong>.</p>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858612-b90a1080-12d5-11ea-95d4-a9cf5582dbd9.png" /></div>

<p>We attach a <strong>head of the same design (3Ã—3 conv and two sibling 1Ã—1 convs) to each level</strong> on our feature pyramid. Because the head slides densely over all locations in all pyramid levels, it is not necessary to have multi-scale anchors on a specific level. Instead, we assign <strong>anchors of a single scale to each level</strong>.</p>

<blockquote>
  <p>Feature Pyramid Networks for Fast R-CNN</p>
</blockquote>

<p>Fast R-CNN is a region-based object detector in which Region-of-Interest (RoI) pooling is used to extract features.
Thus we adapt the assignment strategy of region-based detectors in the case when they are run on image pyramids. Formally, we assign an RoI of width w and height h (on the input image to the network) to the level Pk of our feature pyramid by:</p>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858606-b4ddf300-12d5-11ea-9651-e4f28ef86012.png" /></div>

<p>Intuitively, the above equation means that if the RoIâ€™s scale becomes smaller (say, 1/2 of 224), it should be mapped into a finer-resolution level (say, k = 3). We attach predictor heads to all RoIs of all levels, and they share parameters, regardless of their levels.</p>

<h2 id="experiments">Experiments</h2>

<blockquote>
  <p>Region Proposal with RPN</p>
</blockquote>

<p>Â Â Â Â  We evaluate the COCO-style Average Recall (AR) and
AR on small, medium, and large objects (ARs, ARm, and ARl) following the definitions in  We report results for 100 and 1000 proposals per images (AR100 and AR1k).</p>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858608-b60f2000-12d5-11ea-8351-f944db091268.png" /></div>

<blockquote>
  <p>Object Detection with Fast/Faster R-CNN</p>
</blockquote>

<p>Next we investigate FPN for region-based (non-sliding window) detectors. We evaluate object detection by the COCO-style Average Precision (AP) and PASCAL-style AP (at a single IoU threshold of 0.5). We also report COCO AP on objects of small, medium, and large sizes.</p>

<div style="text-align:center"><img src="https://user-images.githubusercontent.com/57972646/69858609-b7d8e380-12d5-11ea-91e6-4da5175b62d5.png" /></div>

<h2 id="conclusion">Conclusion</h2>

<p>Â Â Â Â  In this paper, authors presented a simple framework for building feature pyramids inside ConvNets. Our method shows significant improvements over several strong baselines and competition winners. Thus, it provides a practical solution for research and applications of feature pyramids, without the need of computing image pyramids. <br />
Â Â Â Â  Finally, the study suggests that despite the strong representational power of deep ConvNets and their implicit robustness to scale variation, it is still critical to explicitly address multi- scale problems using pyramid representations.</p>

:ET