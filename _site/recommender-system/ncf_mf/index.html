<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.22.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Pytorch를 이용한 협업 필터링(Matrix Factorization) 구현 - Dohee’s ML Lab</title>
<meta name="description" content="이번 글에서는 Pytorch와 MovieLens 데이터셋을 이용하여, 협업필터링을 구현하겠습니다. 협업 필터링의 여러 기법 중에서 Matrix Factorization을 사용하겠습니다. 마지막으로 Neural Collaborative Filtering 논문에서 제안한 Generalized Matrix Factorization 모델에 대해서 알아보고, 기존 알고리즘과의 성능 비교 실험을 해보겠습니다.">


  <meta name="author" content="Dohee Jung">
  
  <meta property="article:author" content="Dohee Jung">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Dohee's ML Lab">
<meta property="og:title" content="Pytorch를 이용한 협업 필터링(Matrix Factorization) 구현">
<meta property="og:url" content="https://doheelab.github.io/recommender-system/ncf_mf/">


  <meta property="og:description" content="이번 글에서는 Pytorch와 MovieLens 데이터셋을 이용하여, 협업필터링을 구현하겠습니다. 협업 필터링의 여러 기법 중에서 Matrix Factorization을 사용하겠습니다. 마지막으로 Neural Collaborative Filtering 논문에서 제안한 Generalized Matrix Factorization 모델에 대해서 알아보고, 기존 알고리즘과의 성능 비교 실험을 해보겠습니다.">







  <meta property="article:published_time" content="2021-03-30T22:00:00+09:00">





  

  


<link rel="canonical" href="https://doheelab.github.io/recommender-system/ncf_mf/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Dohee",
      "url": "https://doheelab.github.io/"
    
  }
</script>






<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Dohee's ML Lab Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'] ],
      processEscapes: true,
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
</script>
<script
  type="text/javascript"
  async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"
></script>

  </head>
  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Dohee's ML Lab
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Pytorch를 이용한 협업 필터링(Matrix Factorization) 구현">
    <meta itemprop="description" content="이번 글에서는 Pytorch와 MovieLens 데이터셋을 이용하여, 협업필터링을 구현하겠습니다. 협업 필터링의 여러 기법 중에서 Matrix Factorization을 사용하겠습니다. 마지막으로 Neural Collaborative Filtering 논문에서 제안한 Generalized Matrix Factorization 모델에 대해서 알아보고, 기존 알고리즘과의 성능 비교 실험을 해보겠습니다.">
    <meta itemprop="datePublished" content="2021-03-30T22:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Pytorch를 이용한 협업 필터링(Matrix Factorization) 구현
</h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          5 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>이번 글에서는 <strong>Pytorch</strong>와 <strong>MovieLens</strong> 데이터셋을 이용하여, 협업필터링을 구현하겠습니다. 협업 필터링의 여러 기법 중에서 <strong>Matrix Factorization</strong>을 사용하겠습니다. 마지막으로 <code class="language-plaintext highlighter-rouge">Neural Collaborative Filtering</code> 논문에서 제안한 Generalized Matrix Factorization 모델에 대해서 알아보고, 기존 알고리즘과의 성능 비교 실험을 해보겠습니다.</p>

<h2 id="1-matrix-factorization-소개">1. Matrix Factorization 소개</h2>

<p>유저 벡터($p_u$)와 아이템 벡터($p_i$)가 주어졌을 때, 유저와 아이템의 <code class="language-plaintext highlighter-rouge">상호작용(interaction)</code>을 다음과 같이 내적으로 정의합니다.</p>

<blockquote>
  <p><em>Matrix Factorization Model</em> 
\begin{align*}
y_{ui} = p_u \cdot p_i
\end{align*}</p>

</blockquote>

<p>이를 바탕으로 모델을 정의하면 다음과 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MF</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">user_num</span><span class="p">,</span> <span class="n">item_num</span><span class="p">,</span> <span class="n">factor_num</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MF</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">factor_num</span> <span class="o">=</span> <span class="n">factor_num</span>

        <span class="c1"># 임베딩 저장공간 확보; (num_embeddings, embedding_dim)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">embed_user</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">user_num</span><span class="p">,</span> <span class="n">factor_num</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed_item</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">item_num</span><span class="p">,</span> <span class="n">factor_num</span><span class="p">)</span>
        <span class="n">predict_size</span> <span class="o">=</span> <span class="n">factor_num</span>
        <span class="c1"># 상수 Tensor 생성
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">predict_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">predict_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">cuda</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_init_weight_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_init_weight_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># weight 초기화
</span>        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embed_user</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embed_item</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

        <span class="c1"># bias 초기화
</span>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">m</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="n">embed_user</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embed_user</span><span class="p">(</span><span class="n">user</span><span class="p">)</span>
        <span class="n">embed_item</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embed_item</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="c1"># Tensor의 원소별 곱셈
</span>        <span class="n">output_GMF</span> <span class="o">=</span> <span class="n">embed_user</span> <span class="o">*</span> <span class="n">embed_item</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">output_GMF</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict_layer</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prediction</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="generalized-matrix-factorization">Generalized Matrix Factorization</h2>

<p><strong>GMF</strong>는 이러한 상호작용을 일반화하여 모델의 성능을 향상시키기 위한 모델입니다. 이를 위해 위 식에서 <strong>1. 내적($\cdot$)을 일반화하고</strong>, <strong>2. 활성함수(activation function)를 추가합니다.</strong></p>

<blockquote>
  <p><em>Generalized Matrix Factorization (GMF)</em>
\begin{align*}
y_{ui} = a_{out}(h^T(p_u \odot p_i))
\end{align*}</p>

</blockquote>

<p>이 모델을 구현한 코드는 다음과 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">GMF</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">user_num</span><span class="p">,</span> <span class="n">item_num</span><span class="p">,</span> <span class="n">factor_num</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GMF</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="c1"># 임베딩 저장공간 확보; num_embeddings, embedding_dim
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">embed_user_GMF</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">user_num</span><span class="p">,</span> <span class="n">factor_num</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed_item_GMF</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">item_num</span><span class="p">,</span> <span class="n">factor_num</span><span class="p">)</span>
        <span class="n">predict_size</span> <span class="o">=</span> <span class="n">factor_num</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">predict_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">predict_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_init_weight_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_init_weight_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># weight 초기화
</span>        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embed_user_GMF</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embed_item_GMF</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">predict_layer</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s">"sigmoid"</span><span class="p">)</span>

        <span class="c1"># bias 초기화
</span>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">m</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="n">embed_user_GMF</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embed_user_GMF</span><span class="p">(</span><span class="n">user</span><span class="p">)</span>
        <span class="n">embed_item_GMF</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embed_item_GMF</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="n">output_GMF</span> <span class="o">=</span> <span class="n">embed_user_GMF</span> <span class="o">*</span> <span class="n">embed_item_GMF</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="n">output_GMF</span>

        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict_layer</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prediction</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>손실함수는 <code class="language-plaintext highlighter-rouge">binary cross entropy</code>를, <code class="language-plaintext highlighter-rouge">optimizer</code>는 <code class="language-plaintext highlighter-rouge">Adam</code>을 사용하였습니다. 
이 외의 설정은 다음과 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"batch_size"</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="s">"epochs"</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="s">"factor_num"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="s">"gpu"</span><span class="p">:</span> <span class="s">"0"</span><span class="p">,</span>
    <span class="s">"lr"</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="s">"num_layers"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s">"num_ng"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s">"out"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="s">"test_num_ng"</span><span class="p">:</span> <span class="mi">99</span><span class="p">,</span>
    <span class="s">"top_k"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>전체코드는 다음 링크에서 확인하실 수 있습니다.</p>

<ul>
  <li>Matrix Factorization <a href="https://github.com/doheelab/NCF/blob/master/MF.py">(github)</a></li>
  <li>Generalized Matrix Factorization <a href="https://github.com/doheelab/NCF/blob/master/GMF.py">(github)</a></li>
</ul>

<h2 id="실험결과">실험결과</h2>

<p>20 epoch 동안 학습을 한 결과, <code class="language-plaintext highlighter-rouge">MF</code>의 최고 점수는 <code class="language-plaintext highlighter-rouge">HR = 0.704</code>, <code class="language-plaintext highlighter-rouge">NDCG = 0.422</code>이고, <code class="language-plaintext highlighter-rouge">GMF</code>의 치고 점수는 <code class="language-plaintext highlighter-rouge">HR = 0.706, NDCG = 0.423</code>이 나왔습니다. <code class="language-plaintext highlighter-rouge">GMF</code>의 스코어가 약간 더 높지만, 크게 의미있는 차이는 아닌 것 같습니다. 다만 <code class="language-plaintext highlighter-rouge">GMF</code>는 딥러닝 모델이므로 더 큰 데이터에 대해서 테스트를 하면 의미있는 차이가 나올 수도 있습니다.</p>

<blockquote>
  <p>실험결과 (MF)</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The time elapse of epoch 000 is: 00: 03: 05
HR: 0.514       NDCG: 0.290
The time elapse of epoch 001 is: 00: 03: 01
HR: 0.600       NDCG: 0.342
The time elapse of epoch 002 is: 00: 02: 59
HR: 0.644       NDCG: 0.372
The time elapse of epoch 003 is: 00: 02: 58
HR: 0.669       NDCG: 0.392
The time elapse of epoch 004 is: 00: 03: 05
HR: 0.680       NDCG: 0.401
The time elapse of epoch 005 is: 00: 03: 01
HR: 0.688       NDCG: 0.408
The time elapse of epoch 006 is: 00: 02: 58
HR: 0.694       NDCG: 0.415
The time elapse of epoch 007 is: 00: 03: 00
HR: 0.699       NDCG: 0.418
The time elapse of epoch 008 is: 00: 03: 01
HR: 0.702       NDCG: 0.418
The time elapse of epoch 009 is: 00: 03: 08
HR: 0.698       NDCG: 0.420
The time elapse of epoch 010 is: 00: 03: 04
HR: 0.704       NDCG: 0.422
The time elapse of epoch 011 is: 00: 03: 04
HR: 0.701       NDCG: 0.422
The time elapse of epoch 012 is: 00: 02: 56
HR: 0.704       NDCG: 0.423
The time elapse of epoch 013 is: 00: 02: 52
HR: 0.702       NDCG: 0.421
The time elapse of epoch 014 is: 00: 02: 53
HR: 0.703       NDCG: 0.423
The time elapse of epoch 015 is: 00: 02: 53
HR: 0.701       NDCG: 0.424
The time elapse of epoch 016 is: 00: 02: 52
HR: 0.699       NDCG: 0.419
The time elapse of epoch 017 is: 00: 02: 46
HR: 0.699       NDCG: 0.419
The time elapse of epoch 018 is: 00: 02: 45
HR: 0.697       NDCG: 0.420
The time elapse of epoch 019 is: 00: 02: 46
HR: 0.698       NDCG: 0.421
End. Best epoch 010: HR = 0.704, NDCG = 0.422
</code></pre></div>  </div>
</blockquote>

<blockquote>
  <p>실험결과 (GMF)</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The time elapse of epoch 000 is: 00: 03: 11
HR: 0.572       NDCG: 0.320
The time elapse of epoch 001 is: 00: 03: 07
HR: 0.625       NDCG: 0.360
The time elapse of epoch 002 is: 00: 03: 08
HR: 0.651       NDCG: 0.382
The time elapse of epoch 003 is: 00: 03: 06
HR: 0.665       NDCG: 0.393
The time elapse of epoch 004 is: 00: 03: 03
HR: 0.681       NDCG: 0.404
The time elapse of epoch 005 is: 00: 02: 50
HR: 0.695       NDCG: 0.411
The time elapse of epoch 006 is: 00: 02: 55
HR: 0.699       NDCG: 0.413
The time elapse of epoch 007 is: 00: 02: 55
HR: 0.701       NDCG: 0.418
The time elapse of epoch 008 is: 00: 03: 09
HR: 0.705       NDCG: 0.420
The time elapse of epoch 009 is: 00: 03: 07
HR: 0.703       NDCG: 0.419
The time elapse of epoch 010 is: 00: 03: 03
HR: 0.700       NDCG: 0.420
The time elapse of epoch 011 is: 00: 03: 04
HR: 0.701       NDCG: 0.421
The time elapse of epoch 012 is: 00: 03: 10
HR: 0.702       NDCG: 0.421
The time elapse of epoch 013 is: 00: 03: 06
HR: 0.705       NDCG: 0.423
The time elapse of epoch 014 is: 00: 03: 04
HR: 0.701       NDCG: 0.425
The time elapse of epoch 015 is: 00: 03: 03
HR: 0.703       NDCG: 0.425
The time elapse of epoch 016 is: 00: 03: 07
HR: 0.704       NDCG: 0.425
The time elapse of epoch 017 is: 00: 03: 11
HR: 0.706       NDCG: 0.423
The time elapse of epoch 018 is: 00: 03: 09
HR: 0.702       NDCG: 0.424
The time elapse of epoch 019 is: 00: 03: 10
HR: 0.703       NDCG: 0.426
End. Best epoch 017: HR = 0.706, NDCG = 0.423
</code></pre></div></div>

<h2 id="참고자료">참고자료</h2>

<p>[1] <a href="https://github.com/doheelab/NCF">실습 코드 링크</a></p>

<p>[2] <a href="https://arxiv.org/abs/1708.05031">Neural Collaborative Filtering</a></p>

<p>[3] <a href="https://github.com/guoyang9/NCF">A pytorch GPU implementation of He et al.</a></p>

<p>[4] <a href="https://files.grouplens.org/datasets/movielens/ml-1m-README.txt">movielens dataset</a></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#collaborative-filtering" class="page__taxonomy-item" rel="tag">collaborative-filtering</a><span class="sep">, </span>
    
      <a href="/tags/#machine-learning" class="page__taxonomy-item" rel="tag">machine-learning</a><span class="sep">, </span>
    
      <a href="/tags/#matrix-factorization" class="page__taxonomy-item" rel="tag">matrix-factorization</a><span class="sep">, </span>
    
      <a href="/tags/#mlp" class="page__taxonomy-item" rel="tag">mlp</a><span class="sep">, </span>
    
      <a href="/tags/#neural-network" class="page__taxonomy-item" rel="tag">neural-network</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item" rel="tag">pytorch</a><span class="sep">, </span>
    
      <a href="/tags/#recommender-system" class="page__taxonomy-item" rel="tag">recommender-system</a><span class="sep">, </span>
    
      <a href="/tags/#tensorboard" class="page__taxonomy-item" rel="tag">tensorboard</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#recommender-system" class="page__taxonomy-item" rel="tag">recommender-system</a>
    
    </span>
  </p>


        
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-03-30T22:00:00+09:00">March 30, 2021</time></p>


      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Pytorch%EB%A5%BC+%EC%9D%B4%EC%9A%A9%ED%95%9C+%ED%98%91%EC%97%85+%ED%95%84%ED%84%B0%EB%A7%81%28Matrix+Factorization%29+%EA%B5%AC%ED%98%84%20https%3A%2F%2Fdoheelab.github.io%2Frecommender-system%2Fncf_mf%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdoheelab.github.io%2Frecommender-system%2Fncf_mf%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fdoheelab.github.io%2Frecommender-system%2Fncf_mf%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/recommender-system/ncf_mlp/" class="pagination--pager" title="[Pytorch] Neural Collaborative Filtering - MLP 실험
">Previous</a>
    
    
      <a href="/web-development/jwt/" class="pagination--pager" title="JWT(JSON Web Token)를 활용한 권한 부여(authentication)
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/database/db-normalization/" rel="permalink">[Database] 데이터베이스 정규화의 기초
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">이 글에서는 데이터베이스 정규화에 대해서 알아봅니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/react/setState/" rel="permalink">[React] 비동기적 setState
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">setState는 함수형 컴포넌트 내에서 상태를 관리하게 위해 사용하는 useState를 통해 반환되는 함수입니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/clean-code/slash21_clean_code/" rel="permalink">[Clean Code] 실무에서 바로 쓰는 Frontend Clean Code
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">이 글은 개발자 컨퍼런스 SLASH의 “실무에서 바로 쓰는 Frontend Clean Code” 동영상을 정리한 글입니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/web-development/custom_hook/" rel="permalink">[React] 유용한 Custom hook 만들기
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Custom hook은 React에서 제공하는 hook을 활용하여 사용자가 원하는 기능을 수행하도록 만든 함수를 의미합니다. 이를 통해 hook을 포함한 반복적인 작업을 다른 component에서 쉽게 사용할 수 있게 해줍니다.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Dohee. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
